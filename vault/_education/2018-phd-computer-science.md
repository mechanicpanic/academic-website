---
degree: "Ph.D."
field: "Computer Science"
institution: "Stanford University"
location: "Stanford, CA"
graduation_year: 2018
thesis_title: "Scalable Optimization Methods for Deep Neural Networks"
advisor: "Prof. Distinguished Advisor"
committee:
  - "Prof. Distinguished Advisor"
  - "Prof. Machine Learning Expert"
  - "Prof. Optimization Specialist"
  - "Dr. Industry Representative"
gpa: "3.95/4.0"
honors: "Summa Cum Laude, Outstanding Dissertation Award"
relevant_coursework:
  - "Advanced Machine Learning"
  - "Convex Optimization"
  - "Statistical Learning Theory"
  - "Distributed Systems"
---

# Ph.D. in Computer Science

## Thesis/Dissertation

**Title:** Scalable Optimization Methods for Deep Neural Networks

**Abstract:** This dissertation investigates novel optimization techniques for training deep neural networks at scale. We develop theoretical foundations for adaptive learning rate methods and propose practical algorithms that significantly improve training efficiency. The work includes both theoretical analysis and extensive empirical validation on large-scale datasets.

## Coursework

Key courses that shaped academic foundation:

- **Advanced Machine Learning:** Theoretical foundations of learning algorithms, PAC learning, and statistical learning theory
- **Convex Optimization:** Mathematical optimization techniques with applications to machine learning
- **Statistical Learning Theory:** Probabilistic approaches to learning and generalization bounds
- **Distributed Systems:** Large-scale computing architectures for machine learning applications

## Research Experience

Conducted groundbreaking research in neural network optimization under the supervision of Prof. Distinguished Advisor. Work led to 8 publications in top-tier conferences and formed the foundation for subsequent academic career.

## Awards and Honors

- Outstanding Dissertation Award (2018)
- Stanford Graduate Fellowship (2015-2018)
- Best Paper Award at ICML (2017)
- Google Ph.D. Fellowship in Machine Learning (2016)